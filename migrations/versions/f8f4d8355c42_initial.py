"""initial

Revision ID: f8f4d8355c42
Revises: 
Create Date: 2025-11-29 10:01:20.149702

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'f8f4d8355c42'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('company', schema=None) as batch_op:
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)

    with op.batch_alter_table('data_input', schema=None) as batch_op:
        batch_op.add_column(sa.Column('expected_profit', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('total_investment_cost', sa.Float(), nullable=True))
        batch_op.alter_column('data_input_id',
               existing_type=sa.BIGINT(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
        batch_op.drop_constraint(batch_op.f('data input_id_key'), type_='unique')
        batch_op.drop_column('cost_per_hour')
        batch_op.drop_column('extra_turnover')
        batch_op.drop_column('worked_hours')
        batch_op.drop_column('horizon')
        batch_op.drop_column('days_required')
        batch_op.drop_column('extern_costs')
        batch_op.drop_column('gained_hours')
        batch_op.drop_column('fixed_costs')
        batch_op.drop_column('profit_margin')

    with op.batch_alter_table('requirement', schema=None) as batch_op:
        batch_op.alter_column('requirement_id',
               existing_type=sa.BIGINT(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))

    with op.batch_alter_table('results', schema=None) as batch_op:
        batch_op.add_column(sa.Column('time_to_value_days', sa.BigInteger(), nullable=True))
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)
        batch_op.alter_column('roi_percentage',
               existing_type=sa.REAL(),
               type_=sa.Float(),
               existing_nullable=True)
        batch_op.alter_column('confidence_value',
               existing_type=sa.REAL(),
               type_=sa.Float(),
               existing_nullable=True)
        batch_op.drop_column('time_to_value')
        batch_op.drop_column('old_time_to_value')
        batch_op.drop_column('old_confidence_value')
        batch_op.drop_column('old_roi_percentage')

    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.add_column(sa.Column('role', sa.String(), nullable=False))
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
        batch_op.drop_constraint(batch_op.f('user_id_key'), type_='unique')

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.create_unique_constraint(batch_op.f('user_id_key'), ['id'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)
        batch_op.drop_column('role')

    with op.batch_alter_table('results', schema=None) as batch_op:
        batch_op.add_column(sa.Column('old_roi_percentage', sa.REAL(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('old_confidence_value', sa.REAL(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('old_time_to_value', sa.BIGINT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('time_to_value', sa.BIGINT(), autoincrement=False, nullable=True))
        batch_op.alter_column('confidence_value',
               existing_type=sa.Float(),
               type_=sa.REAL(),
               existing_nullable=True)
        batch_op.alter_column('roi_percentage',
               existing_type=sa.Float(),
               type_=sa.REAL(),
               existing_nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)
        batch_op.drop_column('time_to_value_days')

    with op.batch_alter_table('requirement', schema=None) as batch_op:
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('requirement_id',
               existing_type=sa.BIGINT(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)

    with op.batch_alter_table('data_input', schema=None) as batch_op:
        batch_op.add_column(sa.Column('profit_margin', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('fixed_costs', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('gained_hours', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('extern_costs', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('days_required', sa.BIGINT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('horizon', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('worked_hours', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('extra_turnover', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('cost_per_hour', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.create_unique_constraint(batch_op.f('data input_id_key'), ['data_input_id'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('data_input_id',
               existing_type=sa.BIGINT(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)
        batch_op.drop_column('total_investment_cost')
        batch_op.drop_column('expected_profit')

    with op.batch_alter_table('company', schema=None) as batch_op:
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)

    # ### end Alembic commands ###
